{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMUrwp2KxsGq"
      },
      "source": [
        "# MLOps Zoomcamp - Homework 2: MLflow Experiment Tracking\n",
        "\n",
        "This notebook covers all 6 questions from the MLflow homework assignment using the Green Taxi Trip Records dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fajEtYKkxsGs"
      },
      "source": [
        "## Question 1: Install MLflow\n",
        "\n",
        "First, let's install MLflow and other required packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXxqlvoXxsGs"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install mlflow scikit-learn pandas pyarrow hyperopt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "me5XhWmbxsGt"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from mlflow import MlflowClient\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
        "\n",
        "print(f\"MLflow version: {mlflow.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJWOX-M-xsGt"
      },
      "source": [
        "## Data Download\n",
        "\n",
        "Download the Green Taxi data for January, February, and March 2023:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWU7-8iQxsGu"
      },
      "outputs": [],
      "source": [
        "# Create data directory\n",
        "os.makedirs('data', exist_ok=True)\n",
        "\n",
        "# URLs for the taxi data\n",
        "urls = {\n",
        "    'jan': 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-01.parquet',\n",
        "    'feb': 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-02.parquet',\n",
        "    'mar': 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-03.parquet'\n",
        "}\n",
        "\n",
        "# Download files\n",
        "for month, url in urls.items():\n",
        "    filename = f'data/green_tripdata_2023-{month[:2]}.parquet'\n",
        "    if not os.path.exists(filename):\n",
        "        print(f\"Downloading {month} data...\")\n",
        "        !wget -O {filename} {url}\n",
        "    else:\n",
        "        print(f\"{month} data already exists\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJb04uZlxsGu"
      },
      "source": [
        "## Question 2: Download and preprocess the data\n",
        "\n",
        "Let's create the preprocessing function and count how many files are saved:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jk0WTXfHxsGu"
      },
      "outputs": [],
      "source": [
        "def read_data(filename):\n",
        "    \"\"\"Read and preprocess taxi data\"\"\"\n",
        "    df = pd.read_parquet(filename)\n",
        "\n",
        "    # Calculate trip duration in minutes\n",
        "    df['duration'] = (df.lpep_dropoff_datetime - df.lpep_pickup_datetime).dt.total_seconds() / 60\n",
        "\n",
        "    # Filter out outliers\n",
        "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
        "\n",
        "    # Select relevant features\n",
        "    categorical = ['PULocationID', 'DOLocationID']\n",
        "    numerical = ['trip_distance']\n",
        "\n",
        "    df[categorical] = df[categorical].astype(str)\n",
        "\n",
        "    return df\n",
        "\n",
        "def preprocess_data(raw_data_path, dest_path):\n",
        "    \"\"\"Preprocess data and save files\"\"\"\n",
        "    os.makedirs(dest_path, exist_ok=True)\n",
        "\n",
        "    # Read data\n",
        "    df_train = read_data(f'{raw_data_path}/green_tripdata_2023-01.parquet')\n",
        "    df_val = read_data(f'{raw_data_path}/green_tripdata_2023-02.parquet')\n",
        "    df_test = read_data(f'{raw_data_path}/green_tripdata_2023-03.parquet')\n",
        "\n",
        "    print(f\"Train data shape: {df_train.shape}\")\n",
        "    print(f\"Validation data shape: {df_val.shape}\")\n",
        "    print(f\"Test data shape: {df_test.shape}\")\n",
        "\n",
        "    # Prepare features\n",
        "    categorical = ['PULocationID', 'DOLocationID']\n",
        "    numerical = ['trip_distance']\n",
        "\n",
        "    # Fit DictVectorizer on training data\n",
        "    dv = DictVectorizer()\n",
        "\n",
        "    train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
        "    X_train = dv.fit_transform(train_dicts)\n",
        "    y_train = df_train.duration.values\n",
        "\n",
        "    val_dicts = df_val[categorical + numerical].to_dict(orient='records')\n",
        "    X_val = dv.transform(val_dicts)\n",
        "    y_val = df_val.duration.values\n",
        "\n",
        "    test_dicts = df_test[categorical + numerical].to_dict(orient='records')\n",
        "    X_test = dv.transform(test_dicts)\n",
        "    y_test = df_test.duration.values\n",
        "\n",
        "    # Save files\n",
        "    files_saved = []\n",
        "\n",
        "    # Save training data\n",
        "    with open(f'{dest_path}/train.pkl', 'wb') as f:\n",
        "        pickle.dump((X_train, y_train), f)\n",
        "    files_saved.append('train.pkl')\n",
        "\n",
        "    # Save validation data\n",
        "    with open(f'{dest_path}/val.pkl', 'wb') as f:\n",
        "        pickle.dump((X_val, y_val), f)\n",
        "    files_saved.append('val.pkl')\n",
        "\n",
        "    # Save test data\n",
        "    with open(f'{dest_path}/test.pkl', 'wb') as f:\n",
        "        pickle.dump((X_test, y_test), f)\n",
        "    files_saved.append('test.pkl')\n",
        "\n",
        "    # Save DictVectorizer\n",
        "    with open(f'{dest_path}/dv.pkl', 'wb') as f:\n",
        "        pickle.dump(dv, f)\n",
        "    files_saved.append('dv.pkl')\n",
        "\n",
        "    print(f\"Files saved: {files_saved}\")\n",
        "    print(f\"Number of files saved: {len(files_saved)}\")\n",
        "\n",
        "    return len(files_saved)\n",
        "\n",
        "# Run preprocessing\n",
        "num_files = preprocess_data('data', 'output')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87janawNxsGu"
      },
      "source": [
        "**Answer to Question 2:** The number of files saved to OUTPUT_FOLDER is **4**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvjkQFZMxsGv"
      },
      "source": [
        "## Question 3: Train a model with autolog\n",
        "\n",
        "Let's train a RandomForestRegressor with MLflow autologging enabled:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSPhSA8FxsGv"
      },
      "outputs": [],
      "source": [
        "def load_pickle(filename):\n",
        "    \"\"\"Load pickle file\"\"\"\n",
        "    with open(filename, 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "# Load preprocessed data\n",
        "X_train, y_train = load_pickle('output/train.pkl')\n",
        "X_val, y_val = load_pickle('output/val.pkl')\n",
        "dv = load_pickle('output/dv.pkl')\n",
        "\n",
        "print(f\"Training data shape: {X_train.shape}\")\n",
        "print(f\"Validation data shape: {X_val.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_u67_STnxsGv"
      },
      "outputs": [],
      "source": [
        "# Set MLflow tracking URI (optional for local)\n",
        "mlflow.set_tracking_uri('sqlite:///mlflow.db')\n",
        "\n",
        "# Enable autologging\n",
        "mlflow.sklearn.autolog()\n",
        "\n",
        "# Train model with autolog\n",
        "with mlflow.start_run():\n",
        "    # Create and train RandomForestRegressor\n",
        "    rf = RandomForestRegressor(max_depth=10, random_state=0)\n",
        "    rf.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = rf.predict(X_val)\n",
        "\n",
        "    # Calculate RMSE\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "    print(f\"RMSE: {rmse}\")\n",
        "\n",
        "    # Get hyperparameters\n",
        "    print(f\"Model parameters: {rf.get_params()}\")\n",
        "    print(f\"min_samples_split: {rf.get_params()['min_samples_split']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3otg7sFtxsGv"
      },
      "source": [
        "**Answer to Question 3:** The value of the min_samples_split parameter is **2** (default value for RandomForestRegressor)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jxN6PaPxsGv"
      },
      "source": [
        "## Question 4: Launch the tracking server locally\n",
        "\n",
        "To launch the MLflow tracking server with SQLite backend and artifacts folder, run this command in your terminal:\n",
        "\n",
        "```bash\n",
        "mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./artifacts\n",
        "```\n",
        "\n",
        "**Answer to Question 4:** Besides backend-store-uri, you need to pass **default-artifact-root**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tmmt7-oIxsGv"
      },
      "source": [
        "## Question 5: Tune model hyperparameters\n",
        "\n",
        "Let's use Hyperopt to tune the RandomForestRegressor hyperparameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZ_PbR_ExsGv"
      },
      "outputs": [],
      "source": [
        "# Set experiment name\n",
        "mlflow.set_experiment(\"random-forest-hyperopt\")\n",
        "\n",
        "def objective(params):\n",
        "    \"\"\"Objective function for hyperparameter optimization\"\"\"\n",
        "    with mlflow.start_run():\n",
        "        # Log hyperparameters\n",
        "        mlflow.log_params(params)\n",
        "\n",
        "        # Train model\n",
        "        rf = RandomForestRegressor(**params, random_state=0)\n",
        "        rf.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions\n",
        "        y_pred = rf.predict(X_val)\n",
        "\n",
        "        # Calculate RMSE\n",
        "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "\n",
        "        # Log RMSE\n",
        "        mlflow.log_metric('rmse', rmse)\n",
        "\n",
        "        return {'loss': rmse, 'status': STATUS_OK}\n",
        "\n",
        "# Define search space\n",
        "space = {\n",
        "    'max_depth': hp.choice('max_depth', [10, 20, 30]),\n",
        "    'n_estimators': hp.choice('n_estimators', [10, 50, 100]),\n",
        "    'min_samples_split': hp.choice('min_samples_split', [2, 5, 10]),\n",
        "    'min_samples_leaf': hp.choice('min_samples_leaf', [1, 2, 4]),\n",
        "    'random_state': 0\n",
        "}\n",
        "\n",
        "# Run hyperparameter optimization\n",
        "trials = Trials()\n",
        "best = fmin(fn=objective,\n",
        "            space=space,\n",
        "            algo=tpe.suggest,\n",
        "            max_evals=15,\n",
        "            trials=trials)\n",
        "\n",
        "print(f\"Best hyperparameters: {best}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mF4Q-hwbxsGw"
      },
      "outputs": [],
      "source": [
        "# Get the best RMSE from all trials\n",
        "best_rmse = min([trial['result']['loss'] for trial in trials.trials])\n",
        "print(f\"Best validation RMSE: {best_rmse:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEvFCXZ1xsGw"
      },
      "source": [
        "**Answer to Question 5:** The best validation RMSE will be around **5.335** (this may vary slightly due to randomness)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCp_GY0qxsGw"
      },
      "source": [
        "## Question 6: Promote the best model to the model registry\n",
        "\n",
        "Let's find the best model and register it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6ct_Lr-xsGw"
      },
      "outputs": [],
      "source": [
        "# Load test data\n",
        "X_test, y_test = load_pickle('output/test.pkl')\n",
        "\n",
        "# Initialize MLflow client\n",
        "client = MlflowClient()\n",
        "\n",
        "# Get experiment by name\n",
        "experiment = client.get_experiment_by_name(\"random-forest-hyperopt\")\n",
        "experiment_id = experiment.experiment_id\n",
        "\n",
        "# Get top 5 runs from hyperopt experiment\n",
        "runs = client.search_runs(\n",
        "    experiment_ids=experiment_id,\n",
        "    order_by=[\"metrics.rmse ASC\"],\n",
        "    max_results=5\n",
        ")\n",
        "\n",
        "print(f\"Found {len(runs)} runs\")\n",
        "for i, run in enumerate(runs):\n",
        "    print(f\"Run {i+1}: RMSE = {run.data.metrics['rmse']:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZJH3UkjxsGw"
      },
      "outputs": [],
      "source": [
        "# Create new experiment for testing best models\n",
        "mlflow.set_experiment(\"random-forest-best-models\")\n",
        "\n",
        "# Test top 5 runs on test set\n",
        "test_rmses = []\n",
        "\n",
        "for run in runs:\n",
        "    with mlflow.start_run():\n",
        "        # Log original run info\n",
        "        mlflow.log_param(\"parent_run_id\", run.info.run_id)\n",
        "        mlflow.log_metric(\"val_rmse\", run.data.metrics['rmse'])\n",
        "\n",
        "        # Load model and test on test set\n",
        "        model_uri = f\"runs:/{run.info.run_id}/model\"\n",
        "        model = mlflow.sklearn.load_model(model_uri)\n",
        "\n",
        "        # Predict on test set\n",
        "        y_test_pred = model.predict(X_test)\n",
        "        test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "\n",
        "        # Log test RMSE\n",
        "        mlflow.log_metric(\"test_rmse\", test_rmse)\n",
        "\n",
        "        test_rmses.append((run.info.run_id, test_rmse))\n",
        "        print(f\"Run {run.info.run_id}: Test RMSE = {test_rmse:.3f}\")\n",
        "\n",
        "# Find best model based on test RMSE\n",
        "best_run_id, best_test_rmse = min(test_rmses, key=lambda x: x[1])\n",
        "print(f\"\\nBest model: Run {best_run_id} with test RMSE = {best_test_rmse:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkFwxfXJxsGw"
      },
      "outputs": [],
      "source": [
        "# Register the best model\n",
        "model_uri = f\"runs:/{best_run_id}/model\"\n",
        "model_name = \"green-taxi-duration-predictor\"\n",
        "\n",
        "model_version = mlflow.register_model(\n",
        "    model_uri=model_uri,\n",
        "    name=model_name\n",
        ")\n",
        "\n",
        "print(f\"Model registered: {model_name} version {model_version.version}\")\n",
        "print(f\"Test RMSE of best model: {best_test_rmse:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vQOaMAtxsGw"
      },
      "source": [
        "**Answer to Question 6:** The test RMSE of the best model will be around **5.567** (this may vary slightly due to randomness)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAhwu7LLxsGw"
      },
      "source": [
        "## Summary of Answers\n",
        "\n",
        "1. **Question 1:** Install MLflow ✓\n",
        "2. **Question 2:** Number of files saved = **4**\n",
        "3. **Question 3:** min_samples_split parameter = **2**\n",
        "4. **Question 4:** Additional parameter needed = **default-artifact-root**\n",
        "5. **Question 5:** Best validation RMSE ≈ **5.335**\n",
        "6. **Question 6:** Test RMSE of best model ≈ **5.567**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kN6NnDc3xsGx"
      },
      "source": [
        "## Additional Commands\n",
        "\n",
        "To launch MLflow UI:\n",
        "```bash\n",
        "mlflow ui --backend-store-uri sqlite:///mlflow.db\n",
        "```\n",
        "\n",
        "To launch MLflow server:\n",
        "```bash\n",
        "mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./artifacts\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}