{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59e65c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9623cc53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba7352ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf6b1dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>Airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-01 00:57:55</td>\n",
       "      <td>2024-01-01 01:17:43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>186</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>17.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.70</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 00:03:00</td>\n",
       "      <td>2024-01-01 00:09:36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>140</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.75</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 00:17:06</td>\n",
       "      <td>2024-01-01 00:35:01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>236</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>23.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 00:36:38</td>\n",
       "      <td>2024-01-01 00:44:56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>79</td>\n",
       "      <td>211</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 00:46:51</td>\n",
       "      <td>2024-01-01 00:52:57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>211</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.10</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         2  2024-01-01 00:57:55   2024-01-01 01:17:43              1.0   \n",
       "1         1  2024-01-01 00:03:00   2024-01-01 00:09:36              1.0   \n",
       "2         1  2024-01-01 00:17:06   2024-01-01 00:35:01              1.0   \n",
       "3         1  2024-01-01 00:36:38   2024-01-01 00:44:56              1.0   \n",
       "4         1  2024-01-01 00:46:51   2024-01-01 00:52:57              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           1.72         1.0                  N           186            79   \n",
       "1           1.80         1.0                  N           140           236   \n",
       "2           4.70         1.0                  N           236            79   \n",
       "3           1.40         1.0                  N            79           211   \n",
       "4           0.80         1.0                  N           211           148   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             2         17.7    1.0      0.5        0.00           0.0   \n",
       "1             1         10.0    3.5      0.5        3.75           0.0   \n",
       "2             1         23.3    3.5      0.5        3.00           0.0   \n",
       "3             1         10.0    3.5      0.5        2.00           0.0   \n",
       "4             1          7.9    3.5      0.5        3.20           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  Airport_fee  \n",
       "0                    1.0         22.70                   2.5          0.0  \n",
       "1                    1.0         18.75                   2.5          0.0  \n",
       "2                    1.0         31.30                   2.5          0.0  \n",
       "3                    1.0         17.00                   2.5          0.0  \n",
       "4                    1.0         16.10                   2.5          0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "481fc982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "502971b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.2'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a54788af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2964624, 19)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f29ee7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac9834c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag', 'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount', 'congestion_surcharge', 'Airport_fee']\n"
     ]
    }
   ],
   "source": [
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0592b099",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['duration'] = df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2364983",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['duration'] = df['duration'].dt.total_seconds() / 60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0374aecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data type of the 'duration' column is: float64\n",
      "Standard deviation of trip duration in minutes: 34.851053592192876\n"
     ]
    }
   ],
   "source": [
    "std_dev_duration = df['duration'].std()\n",
    "\n",
    "print(f\"The data type of the 'duration' column is: {df['duration'].dtype}\")\n",
    "print(f\"Standard deviation of trip duration in minutes: {std_dev_duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29692c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records before dropping outliers: 2964624\n",
      "Number of records after dropping outliers (1 to 60 min duration): 2898906\n",
      "Percentage of records remaining: 97.78%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of records before dropping outliers: {len(df)}\")\n",
    "\n",
    "lower_bound_duration = 1\n",
    "upper_bound_duration = 60\n",
    "\n",
    "df_filtered = df[(df['duration'] >= lower_bound_duration) & (df['duration'] <= upper_bound_duration)].copy()\n",
    "print(f\"Number of records after dropping outliers (1 to 60 min duration): {len(df_filtered)}\")\n",
    "\n",
    "\n",
    "percentage_remaining = (len(df_filtered) / len(df)) * 100\n",
    "\n",
    "print(f\"Percentage of records remaining: {percentage_remaining:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d046149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the feature matrix is: (2898906, 518)\n",
      "The dimensionality (number of features) of the matrix after one-hot encoding is: 518\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "categorical_cols = ['PULocationID', 'DOLocationID']\n",
    "df_filtered[categorical_cols] = df_filtered[categorical_cols].fillna(-1).astype(str)\n",
    "\n",
    "records_for_dv = df_filtered[categorical_cols].to_dict(orient='records')\n",
    "\n",
    "dv = DictVectorizer()\n",
    "X_train = dv.fit_transform(records_for_dv)\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "print(f\"The shape of the feature matrix is: {X_train.shape}\")\n",
    "print(f\"The dimensionality (number of features) of the matrix after one-hot encoding is: {num_features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7c0fb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train: (2898906,)\n"
     ]
    }
   ],
   "source": [
    "target = 'duration'\n",
    "y_train = df_filtered[target].values\n",
    "print(f\"Shape of y_train: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "649f36d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (2898906, 518)\n",
      "Shape of y_train: (2898906,)\n",
      "Linear Regression model trained.\n",
      "Mean Squared Error (MSE) on training data: 63.141671060223224\n",
      "Root Mean Squared Error (RMSE) on training data: 7.946173359562653\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "target = 'duration'\n",
    "if 'df_filtered' in locals(): # Check if df_filtered exists\n",
    "    y_train = df_filtered[target].values\n",
    "else:\n",
    "    y_train = df[target].values\n",
    "\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Linear Regression model trained.\")\n",
    "y_pred_train = lr_model.predict(X_train)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "rmse_train = np.sqrt(mse_train)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE) on training data: {mse_train}\")\n",
    "print(f\"Root Mean Squared Error (RMSE) on training data: {rmse_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a80a0d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to free up memory from training data artifacts...\n",
      "Deleted X_train.\n",
      "Deleted y_train.\n",
      "Deleted the main filtered training DataFrame (assumed name: df_filtered).\n",
      "Memory cleanup attempted.\n"
     ]
    }
   ],
   "source": [
    "# CELL TO RUN BEFORE STARTING Q6 DATA LOADING\n",
    "\n",
    "print(\"Attempting to free up memory from training data artifacts...\")\n",
    "\n",
    "# Make sure these variables actually exist from your Q4/Q5 run before trying to delete\n",
    "if 'X_train' in locals():\n",
    "    del X_train\n",
    "    print(\"Deleted X_train.\")\n",
    "if 'y_train' in locals():\n",
    "    del y_train\n",
    "    print(\"Deleted y_train.\")\n",
    "\n",
    "# Assuming your filtered training DataFrame was named df_filtered (from Q3 output)\n",
    "# or if you reassigned it to 'df' after filtering.\n",
    "# Adjust the name if it was different (e.g., df_processed, train_df)\n",
    "if 'df_filtered' in locals() and 'df_val_filtered' not in locals(): # Avoid deleting df_val_filtered prematurely\n",
    "    # This is to delete the DataFrame that was used to create X_train and y_train\n",
    "    # Be careful with the variable name here. It's the one that holds the filtered *training* data.\n",
    "    # If you used 'df' for your main filtered training data, use 'del df'\n",
    "    # For now, I'll assume it was 'df_filtered' as per Q3's output variable name.\n",
    "    # This assumes 'df_val_filtered' is a distinct variable for validation.\n",
    "    try:\n",
    "        # Check if df_filtered is indeed the training dataframe by checking its length from previous Q3/Q4 outputs\n",
    "        # e.g. if training df_filtered had 2898906 rows.\n",
    "        # This is a bit heuristic, be careful.\n",
    "        if len(df_filtered) == 2898906: # Number of rows from your Q4 X_train shape\n",
    "             del df_filtered\n",
    "             print(\"Deleted the main filtered training DataFrame (assumed name: df_filtered).\")\n",
    "    except NameError:\n",
    "        print(\"Training DataFrame (df_filtered) not found or already deleted.\")\n",
    "\n",
    "\n",
    "import gc\n",
    "gc.collect() # Trigger garbage collection\n",
    "print(\"Memory cleanup attempted.\")\n",
    "\n",
    "# Crucially, 'dv' (fitted DictVectorizer) and 'lr_model' (trained LinearRegression)\n",
    "# MUST remain in memory. Do NOT delete them.\n",
    "# Also, 'categorical_cols', 'target', 'lower_bound_duration', 'upper_bound_duration' must remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1faad433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Question 6 processing (memory optimized)...\n",
      "Loading validation data from: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-02.parquet\n",
      "Loaded validation data with 3007526 records.\n",
      "Calculated duration for validation data.\n",
      "Validation data after filtering outliers: 2938060 records.\n",
      "Transforming validation data with DictVectorizer (using generator)...\n",
      "Shape of X_val: (2938060, 518)\n",
      "Shape of y_val: (2938060,)\n",
      "Making predictions on validation data...\n",
      "Mean Squared Error (MSE) on validation data: 65.98935055442578\n",
      "Root Mean Squared Error (RMSE) on validation data: 8.123382950127723\n",
      "\n",
      "Final RMSE on validation (for Question 6): 8.123382950127723\n"
     ]
    }
   ],
   "source": [
    "# --- Question 6: RMSE on Validation Data (Revised for Memory) ---\n",
    "\n",
    "# Ensure 'dv' (fitted DictVectorizer), 'lr_model' (trained LinearRegression model),\n",
    "# 'categorical_cols', 'target', 'lower_bound_duration', 'upper_bound_duration'\n",
    "# are defined and in memory. Run the cleanup cell above this one first.\n",
    "\n",
    "print(\"Starting Question 6 processing (memory optimized)...\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import gc # For garbage collection\n",
    "\n",
    "# 1. Load Validation Data\n",
    "# ADITYA: ENSURE THIS URL IS CORRECT FOR YOUR FEB 2024 (or other) VALIDATION DATA\n",
    "validation_data_url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-02.parquet'\n",
    "\n",
    "print(f\"Loading validation data from: {validation_data_url}\")\n",
    "df_val = pd.read_parquet(validation_data_url)\n",
    "print(f\"Loaded validation data with {len(df_val)} records.\")\n",
    "\n",
    "# 2. Apply ALL Preprocessing Steps\n",
    "\n",
    "# a) Calculate 'duration'\n",
    "df_val['duration'] = df_val['tpep_dropoff_datetime'] - df_val['tpep_pickup_datetime']\n",
    "df_val['duration'] = df_val['duration'].dt.total_seconds() / 60\n",
    "print(\"Calculated duration for validation data.\")\n",
    "\n",
    "# b) Filter outliers\n",
    "df_val_filtered = df_val[(df_val['duration'] >= lower_bound_duration) & (df_val['duration'] <= upper_bound_duration)].copy()\n",
    "del df_val # Free memory from the original large unfiltered validation dataframe\n",
    "gc.collect()\n",
    "print(f\"Validation data after filtering outliers: {len(df_val_filtered)} records.\")\n",
    "\n",
    "rmse_val = \"Error: Could not compute.\"\n",
    "\n",
    "if len(df_val_filtered) == 0:\n",
    "    print(\"No data remains after filtering the validation set. Cannot proceed.\")\n",
    "else:\n",
    "    # c) Prepare categorical features (on df_val_filtered)\n",
    "    df_val_filtered[categorical_cols] = df_val_filtered[categorical_cols].fillna(-1).astype(str)\n",
    "    \n",
    "    # Define a generator for DictVectorizer\n",
    "    def records_generator_for_dv(df, Pcols):\n",
    "        for record_tuple in df[Pcols].itertuples(index=False):\n",
    "            yield dict(zip(Pcols, record_tuple))\n",
    "\n",
    "    # d) Transform using the FITTED DictVectorizer with the generator\n",
    "    print(\"Transforming validation data with DictVectorizer (using generator)...\")\n",
    "    # 'dv' is the DictVectorizer fitted on training data\n",
    "    X_val = dv.transform(records_generator_for_dv(df_val_filtered, categorical_cols))\n",
    "    # The generator is consumed by transform, no separate del needed for val_records_for_dv\n",
    "    gc.collect()\n",
    "    print(f\"Shape of X_val: {X_val.shape}\")\n",
    "\n",
    "    # 3. Prepare Target Variable (y_val)\n",
    "    y_val = df_val_filtered[target].values\n",
    "    # Now that X_val and y_val are created, we can delete df_val_filtered\n",
    "    del df_val_filtered \n",
    "    gc.collect()\n",
    "    print(f\"Shape of y_val: {y_val.shape}\")\n",
    "\n",
    "    if X_val.shape[0] > 0 and X_val.shape[0] == y_val.shape[0]:\n",
    "        # 4. Make Predictions\n",
    "        print(\"Making predictions on validation data...\")\n",
    "        y_pred_val = lr_model.predict(X_val)\n",
    "\n",
    "        # 5. Calculate RMSE\n",
    "        mse_val = mean_squared_error(y_val, y_pred_val)\n",
    "        rmse_val = np.sqrt(mse_val)\n",
    "\n",
    "        print(f\"Mean Squared Error (MSE) on validation data: {mse_val}\")\n",
    "        print(f\"Root Mean Squared Error (RMSE) on validation data: {rmse_val}\")\n",
    "    else:\n",
    "        print(\"Skipping RMSE calculation: Shape mismatch or empty data for X_val/y_val.\")\n",
    "\n",
    "# Final output for the question\n",
    "print(f\"\\nFinal RMSE on validation (for Question 6): {rmse_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95463f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
